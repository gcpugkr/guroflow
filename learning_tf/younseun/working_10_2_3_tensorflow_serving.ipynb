{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_serving'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f1a182c253df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_serving\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexample\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmnist_input_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_serving'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.saved_model import builder as saved_model_builder\n",
    "from tensorflow.python.saved_model import signature_constants\n",
    "from tensorflow.python.saved_model import signature_def_utils\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from tensorflow.python.saved_model import utils\n",
    "from tensorflow.python.util import compat\n",
    "from tensorflow_serving.example import mnist_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.saved_model import builder \n",
    "                                           as saved_model_builder\n",
    "from tensorflow.python.saved_model import signature_constants\n",
    "from tensorflow.python.saved_model import signature_def_utils\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from tensorflow.python.saved_model import utils\n",
    "from tensorflow.python.util import compat\n",
    "from tensorflow_serving.example import mnist_input_data\n",
    "\n",
    "tf.app.flags.DEFINE_integer('training_iteration', 10,\n",
    "                            'number of training iterations.')\n",
    "tf.app.flags.DEFINE_integer(\n",
    "                 'model_version', 1, 'version number of the model.')\n",
    "tf.app.flags.DEFINE_string('work_dir', '/tmp', 'Working directory.')\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial,dtype='float')\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial,dtype='float')\n",
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def main(_):\n",
    "    if len(sys.argv) < 2 or sys.argv[-1].startswith('-'):\n",
    "        print('Usage: mnist_export.py [--training_iteration=x] '\n",
    "              '[--model_version=y] export_dir')\n",
    "        sys.exit(-1)\n",
    "    if FLAGS.training_iteration <= 0:\n",
    "        print('Please specify a positive \n",
    "                                 value for training iteration.')\n",
    "        sys.exit(-1)\n",
    "    if FLAGS.model_version <= 0:\n",
    "        print ('Please specify a positive \n",
    "                                     value for version number.')\n",
    "        sys.exit(-1)\n",
    "    \n",
    "\n",
    "    print('Training...')\n",
    "    mnist = mnist_input_data.read_data_sets(\n",
    "                                  FLAGS.work_dir, one_hot=True)\n",
    "    sess = tf.InteractiveSession()\n",
    "    serialized_tf_example = tf.placeholder(\n",
    "                                  tf.string, name='tf_example')\n",
    "    feature_configs = {'x': tf.FixedLenFeature(shape=[784],\\ \n",
    "                                            dtype=tf.float32),}\n",
    "    tf_example = tf.parse_example(serialized_tf_example, \n",
    "                                                feature_configs)\n",
    "    \n",
    "    \n",
    "    x = tf.identity(tf_example['x'], name='x')  \n",
    "    y_ = tf.placeholder('float', shape=[None, 10])\n",
    "\n",
    "    W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "    b_conv1 = bias_variable([32])\n",
    "    x_image = tf.reshape(x, [-1,28,28,1])\n",
    "\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "    W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "    b_conv2 = bias_variable([64])\n",
    "\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "    h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "\n",
    "    W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "    b_fc1 = bias_variable([1024])\n",
    "\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "    W_fc2 = weight_variable([1024, 10])\n",
    "    b_fc2 = bias_variable([10])\n",
    "\n",
    "    y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "    \n",
    " \n",
    "    y = tf.nn.softmax(y_conv, name='y')\n",
    "    cross_entropy = -tf.reduce_sum(y_ * tf.log(y_conv))\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).\\\n",
    "                                          minimize(cross_entropy)\n",
    "   \n",
    "    \n",
    "    values, indices = tf.nn.top_k(y_conv, 10)\n",
    "    prediction_classes = tf.contrib.lookup.index_to_string(\n",
    "      tf.to_int64(indices), \n",
    "      mapping=tf.constant([str(i) for i in xrange(10)]))\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for _ in range(FLAGS.training_iteration):\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        \n",
    "        train_step.run(feed_dict={x: batch[0], \n",
    "                                 y_: batch[1], keep_prob: 0.5})\n",
    "        print(_)\n",
    "        correct_prediction = tf.equal(tf.argmax(y_conv,1), \n",
    "                                         tf.argmax(y_,1))\n",
    "\n",
    "    \n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "                       y_: mnist.test.labels})\n",
    "    \n",
    "    print('training accuracy %g' % accuracy.eval(feed_dict={\n",
    "        x: mnist.test.images, \n",
    "        y_: mnist.test.labels, keep_prob: 1.0}))\n",
    "\n",
    "    print('training is finished!')\n",
    "    \n",
    "    export_path_base = sys.argv[-1]\n",
    "    export_path = os.path.join(\n",
    "      compat.as_bytes(export_path_base),\n",
    "      compat.as_bytes(str(FLAGS.model_version)))\n",
    "    print 'Exporting trained model to', export_path\n",
    "    builder = saved_model_builder.SavedModelBuilder(export_path)\n",
    "\n",
    "    classification_inputs = utils.build_tensor_info(\n",
    "                                             serialized_tf_example)\n",
    "    classification_outputs_classes = utils.build_tensor_info(\n",
    "                                             prediction_classes)\n",
    "    classification_outputs_scores = utils.build_tensor_info(values)\n",
    "\n",
    "    classification_signature = signature_def_utils.\\\n",
    "      build_signature_def(\n",
    "      inputs={signature_constants.CLASSIFY_INPUTS:\\ \n",
    "                           classification_inputs},\n",
    "      outputs={\n",
    "          signature_constants.CLASSIFY_OUTPUT_CLASSES:\n",
    "              classification_outputs_classes,\n",
    "          signature_constants.CLASSIFY_OUTPUT_SCORES:\n",
    "              classification_outputs_scores\n",
    "      },\n",
    "      method_name=signature_constants.CLASSIFY_METHOD_NAME)\n",
    "\n",
    "    tensor_info_x = utils.build_tensor_info(x)\n",
    "    tensor_info_y = utils.build_tensor_info(y_conv)\n",
    "\n",
    "    prediction_signature = signature_def_utils.build_signature_def(\n",
    "      inputs={'images': tensor_info_x},\n",
    "      outputs={'scores': tensor_info_y},\n",
    "      method_name=signature_constants.PREDICT_METHOD_NAME)\n",
    "\n",
    "    legacy_init_op = tf.group(tf.initialize_all_tables(), \n",
    "                                   name='legacy_init_op')\n",
    "    builder.add_meta_graph_and_variables(\n",
    "      sess, [tag_constants.SERVING],\n",
    "      signature_def_map={\n",
    "          'predict_images':\n",
    "              prediction_signature,\n",
    "          signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:\n",
    "              classification_signature,\n",
    "      },\n",
    "      legacy_init_op=legacy_init_op)\n",
    "\n",
    "    builder.save()\n",
    "\n",
    "    print('new model exported!')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
